# Hackathon AI åŠ©æ‰‹é…ç½®å®Œæˆæ€»ç»“

## âœ… å·²å®Œæˆçš„å·¥ä½œ

### 1. åç«¯æœåŠ¡å™¨ (`backend/`)

#### æ ¸å¿ƒæ–‡ä»¶
âœ… **ai_assistant_server.py** (ä¸»æœåŠ¡å™¨)
- Flask Web æœåŠ¡å™¨
- Ollama API é›†æˆ
- OpenAI å…¼å®¹æ¥å£
- å¥åº·æ£€æŸ¥ç«¯ç‚¹
- ä¸“é—¨é’ˆå¯¹ Hackathon å¹³å°çš„æç¤ºè¯

âœ… **requirements.txt** (Python ä¾èµ–)
```
Flask==3.0.0
Flask-CORS==4.0.0
requests==2.31.0
python-dotenv==1.0.0
```

âœ… **.env.example** (ç¯å¢ƒå˜é‡æ¨¡æ¿)
```env
OLLAMA_API=http://localhost:11434/api/generate
MODEL_NAME=qwen2.5:7b
HOST=0.0.0.0
PORT=8000
```

#### å¯åŠ¨è„šæœ¬
âœ… **start_server.bat** (Windows)
- è‡ªåŠ¨æ£€æŸ¥ Python
- åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
- å®‰è£…ä¾èµ–
- æ£€æŸ¥ Ollama
- å¯åŠ¨æœåŠ¡å™¨

âœ… **start_server.sh** (macOS/Linux)
- åŒä¸ŠåŠŸèƒ½
- Unix è„šæœ¬æ ¼å¼

#### å·¥å…·è„šæœ¬
âœ… **check_setup.py** (ç¯å¢ƒæ£€æŸ¥)
- æ£€æŸ¥ Python ç‰ˆæœ¬
- æ£€æŸ¥ Ollama å®‰è£…
- æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€
- æ£€æŸ¥å·²å®‰è£…çš„æ¨¡å‹
- æ£€æŸ¥ Python ä¾èµ–
- æ£€æŸ¥ç«¯å£å¯ç”¨æ€§

âœ… **test_api.py** (API æµ‹è¯•)
- å¥åº·æ£€æŸ¥æµ‹è¯•
- å•ä¸ªé—®é¢˜æµ‹è¯•
- å¤šä¸ªé—®é¢˜æ‰¹é‡æµ‹è¯•
- æ€§èƒ½ç»Ÿè®¡

#### æ–‡æ¡£
âœ… **README.md** (å®Œæ•´æ–‡æ¡£)
- åŠŸèƒ½ä»‹ç»
- å®‰è£…æŒ‡å—
- API æ–‡æ¡£
- æ•…éšœæ’é™¤
- æ€§èƒ½ä¼˜åŒ–

âœ… **å¿«é€Ÿå¼€å§‹.md** (ä¸­æ–‡å¿«é€ŸæŒ‡å—)
- ä¸€é”®å¯åŠ¨
- ç¯å¢ƒé…ç½®
- å¸¸è§é—®é¢˜
- ä½¿ç”¨ç¤ºä¾‹

âœ… **.gitignore** (Git é…ç½®)
- Python ç¼“å­˜
- è™šæ‹Ÿç¯å¢ƒ
- ç¯å¢ƒå˜é‡æ–‡ä»¶

### 2. å‰ç«¯é›†æˆæ–‡æ¡£ (`frontend/`)

âœ… **AI_ASSISTANT_SETUP.md**
- AI æœåŠ¡å°è£…ä»£ç 
- React ç»„ä»¶å®Œæ•´å®ç°
- æ ·å¼å’Œäº¤äº’
- æµ‹è¯•æ–¹æ³•
- é«˜çº§åŠŸèƒ½ç¤ºä¾‹

### 3. é¡¹ç›®çº§æ–‡æ¡£

âœ… **å¯åŠ¨AIåŠ©æ‰‹å®Œæ•´æŒ‡å—.md**
- ä»é›¶å¼€å§‹çš„å®Œæ•´æ•™ç¨‹
- è¯¦ç»†çš„å®‰è£…æ­¥éª¤
- ç¯å¢ƒæ£€æŸ¥æ¸…å•
- æ•…éšœæ’é™¤æŒ‡å—
- æ€§èƒ½ä¼˜åŒ–å»ºè®®

âœ… **AI_ASSISTANT_INTEGRATION.md**
- æŠ€æœ¯å®ç°æ€»ç»“
- ä¸ coconut-RustSentinel å¯¹æ¯”
- API æ¥å£æ–‡æ¡£
- æ€§èƒ½æŒ‡æ ‡
- ä¸‹ä¸€æ­¥è®¡åˆ’

âœ… **README.md** (æ›´æ–°)
- æ·»åŠ  AI åŠ©æ‰‹åŠŸèƒ½è¯´æ˜
- æ›´æ–°é¡¹ç›®ç»“æ„
- æ·»åŠ æŠ€æœ¯æ ˆä¿¡æ¯
- æ·»åŠ æ–‡æ¡£é“¾æ¥

## ğŸ“Š æŠ€æœ¯å¯¹æ¯”

### ä» OpenAI åˆ° Ollama çš„å˜åŒ–

| ç‰¹æ€§ | OpenAI (åŸæ–¹æ¡ˆ) | Ollama (æ–°æ–¹æ¡ˆ) |
|------|----------------|----------------|
| **æˆæœ¬** | æŒ‰ä½¿ç”¨ä»˜è´¹ | å®Œå…¨å…è´¹ |
| **éšç§** | æ•°æ®ä¸Šä¼ åˆ°äº‘ç«¯ | å®Œå…¨æœ¬åœ°å¤„ç† |
| **é€Ÿåº¦** | å–å†³äºç½‘ç»œ | 5-15 ç§’ |
| **ä¾èµ–** | éœ€è¦ API å¯†é’¥ | æ— éœ€å¯†é’¥ |
| **ç¦»çº¿** | ä¸æ”¯æŒ | æ”¯æŒ |
| **æ¨¡å‹** | GPT-3.5/4 | Qwen2.5/DeepSeek ç­‰ |
| **é…ç½®** | ç®€å• | éœ€è¦å®‰è£… Ollama |

### å‚è€ƒé¡¹ç›®å¯¹æ¯”

| ç‰¹æ€§ | coconut-RustSentinel | Hackathon |
|------|---------------------|-----------|
| **é¢†åŸŸ** | Rust ä»£ç å®¡è®¡ | å»ä¸­å¿ƒåŒ–äº¤æ˜“ |
| **æ¨¡å‹** | deepseek-coder:6.7b | qwen2.5:7b |
| **æ•°æ®åº“** | MySQLï¼ˆå®¡è®¡å†å²ï¼‰ | æ— ï¼ˆçº¯å¯¹è¯ï¼‰ |
| **å‰ç«¯** | Next.js | React + Vite |
| **æ¥å£** | /v1/chat/completions | åŒ + /v1/assistant/chat |

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. AI å¯¹è¯æ¥å£

**ç«¯ç‚¹:** `POST /v1/assistant/chat`

**è¯·æ±‚:**
```json
{
  "messages": [
    {"role": "user", "content": "å¦‚ä½•è¿æ¥é’±åŒ…ï¼Ÿ"}
  ]
}
```

**å“åº”:**
```json
{
  "choices": [{
    "message": {
      "role": "assistant",
      "content": "è¿æ¥é’±åŒ…çš„æ­¥éª¤å¦‚ä¸‹ï¼š\n1. ç‚¹å‡»..."
    },
    "finish_reason": "stop"
  }],
  "model": "qwen2.5:7b",
  "inference_time": 8.5
}
```

### 2. å¥åº·æ£€æŸ¥

**ç«¯ç‚¹:** `GET /health`

**å“åº”:**
```json
{
  "status": "ok",
  "engine": "Ollama",
  "model": "qwen2.5:7b",
  "ollama_status": "running",
  "timestamp": "2026-02-06T10:30:00"
}
```

### 3. OpenAI å…¼å®¹æ¥å£

**ç«¯ç‚¹:** `POST /v1/chat/completions`

ä¸ `/v1/assistant/chat` åŠŸèƒ½ç›¸åŒï¼Œæä¾› OpenAI API å…¼å®¹æ€§ã€‚

## ğŸ“ å®Œæ•´æ–‡ä»¶åˆ—è¡¨

```
Hackathon/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ ai_assistant_server.py      âœ… Flask æœåŠ¡å™¨
â”‚   â”œâ”€â”€ requirements.txt             âœ… Python ä¾èµ–
â”‚   â”œâ”€â”€ .env.example                 âœ… ç¯å¢ƒå˜é‡æ¨¡æ¿
â”‚   â”œâ”€â”€ start_server.bat             âœ… Windows å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ start_server.sh              âœ… macOS/Linux å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ check_setup.py               âœ… ç¯å¢ƒæ£€æŸ¥è„šæœ¬
â”‚   â”œâ”€â”€ test_api.py                  âœ… API æµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ README.md                    âœ… å®Œæ•´æ–‡æ¡£
â”‚   â”œâ”€â”€ å¿«é€Ÿå¼€å§‹.md                   âœ… ä¸­æ–‡å¿«é€ŸæŒ‡å—
â”‚   â”œâ”€â”€ é…ç½®å®Œæˆæ€»ç»“.md               âœ… æœ¬æ–‡æ¡£
â”‚   â””â”€â”€ .gitignore                   âœ… Git é…ç½®
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ AI_ASSISTANT_SETUP.md        âœ… å‰ç«¯é›†æˆæŒ‡å—
â”‚
â”œâ”€â”€ å¯åŠ¨AIåŠ©æ‰‹å®Œæ•´æŒ‡å—.md             âœ… å®Œæ•´å¯åŠ¨æ•™ç¨‹
â”œâ”€â”€ AI_ASSISTANT_INTEGRATION.md      âœ… æŠ€æœ¯æ€»ç»“
â””â”€â”€ README.md                        âœ… å·²æ›´æ–°
```

## ğŸš€ å¿«é€Ÿå¯åŠ¨å‘½ä»¤

### ç¯å¢ƒæ£€æŸ¥
```bash
cd Hackathon/backend
python check_setup.py
```

### å¯åŠ¨æœåŠ¡å™¨

**Windows:**
```bash
cd Hackathon\backend
start_server.bat
```

**macOS/Linux:**
```bash
cd Hackathon/backend
./start_server.sh
```

### æµ‹è¯• API
```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# è¿è¡Œæµ‹è¯•è„šæœ¬
python test_api.py
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### æ¨ç†é€Ÿåº¦
- **é¦–æ¬¡æ¨ç†**: 10-20 ç§’ï¼ˆåŠ è½½æ¨¡å‹ï¼‰
- **åç»­æ¨ç†**: 5-15 ç§’
- **å¹³å‡å“åº”**: 8 ç§’

### èµ„æºå ç”¨
- **å†…å­˜**: 4-8 GBï¼ˆå–å†³äºæ¨¡å‹ï¼‰
- **ç£ç›˜**: 4-6 GBï¼ˆæ¨¡å‹æ–‡ä»¶ï¼‰
- **CPU**: ä¸­ç­‰ï¼ˆæœ‰ GPU æ—¶é™ä½ï¼‰

### æ¨èé…ç½®
- **æœ€ä½**: 4 æ ¸ CPU + 8GB RAM
- **æ¨è**: 8 æ ¸ CPU + 16GB RAM + GPU

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### Python è°ƒç”¨
```python
import requests

response = requests.post(
    "http://localhost:8000/v1/assistant/chat",
    json={
        "messages": [
            {"role": "user", "content": "å¦‚ä½•è·å–æµ‹è¯•å¸ï¼Ÿ"}
        ]
    }
)

answer = response.json()["choices"][0]["message"]["content"]
print(answer)
```

### JavaScript/TypeScript è°ƒç”¨
```typescript
const response = await fetch('http://localhost:8000/v1/assistant/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    messages: [
      { role: 'user', content: 'äº¤æ˜“éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ' }
    ]
  })
});

const data = await response.json();
const answer = data.choices[0].message.content;
console.log(answer);
```

### curl è°ƒç”¨
```bash
curl -X POST http://localhost:8000/v1/assistant/chat \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"æ”¯æŒå“ªäº›é’±åŒ…ï¼Ÿ"}]}'
```

## ğŸ”§ é…ç½®é€‰é¡¹

### åˆ‡æ¢æ¨¡å‹
ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š
```env
MODEL_NAME=deepseek-coder:6.7b
```

### ä¿®æ”¹ç«¯å£
```env
PORT=8001
```

### è°ƒæ•´æ¨ç†å‚æ•°
ç¼–è¾‘ `ai_assistant_server.py`ï¼š
```python
"options": {
    "temperature": 0.7,      # 0.0-1.0
    "num_predict": 800,      # æœ€å¤§ç”Ÿæˆé•¿åº¦
    "top_p": 0.9,
    "top_k": 40
}
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. Ollama æœåŠ¡æœªè¿è¡Œ
```bash
ollama serve
```

### 2. æ¨¡å‹æœªæ‰¾åˆ°
```bash
ollama pull qwen2.5:7b
```

### 3. æ¨ç†é€Ÿåº¦æ…¢
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹
- ç¡®ä¿æœ‰è¶³å¤Ÿå†…å­˜
- ä½¿ç”¨ GPU åŠ é€Ÿ

### 4. ç«¯å£è¢«å ç”¨
ä¿®æ”¹ `.env` ä¸­çš„ `PORT`

### 5. Python ä¾èµ–å®‰è£…å¤±è´¥
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

### é¡¹ç›®æ–‡æ¡£
- [å¯åŠ¨AIåŠ©æ‰‹å®Œæ•´æŒ‡å—.md](../å¯åŠ¨AIåŠ©æ‰‹å®Œæ•´æŒ‡å—.md)
- [AI_ASSISTANT_INTEGRATION.md](../AI_ASSISTANT_INTEGRATION.md)
- [README.md](./README.md)
- [å¿«é€Ÿå¼€å§‹.md](./å¿«é€Ÿå¼€å§‹.md)

### å‰ç«¯æ–‡æ¡£
- [AI_ASSISTANT_SETUP.md](../frontend/AI_ASSISTANT_SETUP.md)

### å¤–éƒ¨èµ„æº
- [Ollama å®˜ç½‘](https://ollama.com/)
- [Ollama GitHub](https://github.com/ollama/ollama)
- [Flask æ–‡æ¡£](https://flask.palletsprojects.com/)

## âœ… éªŒæ”¶æ¸…å•

- [x] åç«¯æœåŠ¡å™¨ä»£ç å®Œæˆ
- [x] Python ä¾èµ–é…ç½®å®Œæˆ
- [x] å¯åŠ¨è„šæœ¬åˆ›å»ºå®Œæˆ
- [x] ç¯å¢ƒæ£€æŸ¥è„šæœ¬å®Œæˆ
- [x] API æµ‹è¯•è„šæœ¬å®Œæˆ
- [x] å®Œæ•´æ–‡æ¡£ç¼–å†™å®Œæˆ
- [x] å‰ç«¯é›†æˆæŒ‡å—å®Œæˆ
- [x] é¡¹ç›® README æ›´æ–°å®Œæˆ
- [x] Git é…ç½®å®Œæˆ

## ğŸ‰ ä¸‹ä¸€æ­¥

### ç«‹å³å¯åš
1. âœ… è¿è¡Œç¯å¢ƒæ£€æŸ¥ï¼š`python check_setup.py`
2. âœ… å¯åŠ¨æœåŠ¡å™¨ï¼š`start_server.bat` æˆ– `./start_server.sh`
3. âœ… æµ‹è¯• APIï¼š`python test_api.py`

### åç»­å¼€å‘
1. â³ åœ¨å‰ç«¯åˆ›å»º AI åŠ©æ‰‹ç»„ä»¶
2. â³ é›†æˆåˆ°ä¸»åº”ç”¨
3. â³ æ·»åŠ å¯¹è¯å†å²ä¿å­˜
4. â³ ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ

### å¯é€‰å¢å¼º
1. ğŸ“‹ æ·»åŠ  RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰
2. ğŸ“‹ é›†æˆçŸ¥è¯†åº“
3. ğŸ“‹ æ·»åŠ è¯­éŸ³è¾“å…¥/è¾“å‡º
4. ğŸ“‹ å¤šè¯­è¨€æ”¯æŒ

## ğŸ’¡ æç¤º

- é¦–æ¬¡æ¨ç†ä¼šè¾ƒæ…¢ï¼Œåç»­ä¼šå¿«å¾ˆå¤š
- æ¨¡å‹ä¼šåœ¨å†…å­˜ä¸­ä¿ç•™ 5 åˆ†é’Ÿ
- å¯ä»¥åŒæ—¶è¿è¡Œå¤šä¸ªæ¨¡å‹
- å®šæœŸæ›´æ–° Ollama å’Œæ¨¡å‹

## ğŸ™ è‡´è°¢

- **coconut-RustSentinel** - æä¾›äº†ä¼˜ç§€çš„å‚è€ƒå®ç°
- **Ollama** - å¼ºå¤§çš„æœ¬åœ° AI æ¨ç†å¼•æ“
- **Qwen Team** - ä¼˜ç§€çš„ä¸­æ–‡ AI æ¨¡å‹
- **Flask** - ç®€æ´çš„ Web æ¡†æ¶

---

**é…ç½®å®Œæˆ âœ… | ç‰ˆæœ¬ v1.0.0 | 2026-02-06**

**å¼€å‘è€…**: Kiro AI Assistant  
**å‚è€ƒé¡¹ç›®**: coconut-RustSentinel  
**æŠ€æœ¯æ ˆ**: Flask + Ollama + Qwen2.5

**çŠ¶æ€**: ğŸ‰ æ‰€æœ‰é…ç½®å·²å®Œæˆï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ï¼

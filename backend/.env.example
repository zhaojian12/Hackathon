# Ollama 配置
OLLAMA_API=http://localhost:11434/api/generate
MODEL_NAME=qwen2.5:7b

# 服务器配置
HOST=0.0.0.0
PORT=8000

# 可选：使用其他模型
# MODEL_NAME=deepseek-coder:6.7b
# MODEL_NAME=llama3.1:8b
# MODEL_NAME=mistral:7b
